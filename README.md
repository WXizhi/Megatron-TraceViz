# Megatron-TraceViz

## 1. Introduction

**Megatron-TraceViz** is an analysis and visualization toolset for Large Language Model (LLM) training. It processes trace files generated by the PyTorch Profiler during **Megatron-LM** distributed training.

By leveraging **Perfetto SQL**, the tool bridges the gap between low-level CUDA kernels and high-level training semantics (TP/PP/DP/EP). It categorizes raw kernel data into training phases, enabling developers to analyze computation/communication overlaps and identify bottlenecks in complex distributed environments.

---

## 2. Per-Rank Trace Analysis

### 2.1 `core_analyzer.py` (Core Logic)
The primary engine for parsing and categorizing individual trace files. It uses a `SliceCollector` to partition raw traces into structured categories:
* **Forward/Backward (FWD/BWD):** Separates computation and communication for both phases, including recomputation logic. Communication extracted here primarily belongs to **Tensor Parallel (TP)** and **Expert Parallel (EP)** operations.
* **Parallelism Communication:** Specifically isolates **Data Parallel (DP)** and **Pipeline Parallel (PP)** communication slices.
* **Optimizer:** Isolates optimizer-specific computation kernels.

**Key Impact:** Transforms messy `.json` traces into structured `.parquet` files of **classified kernels** for granular iteration analysis.

### 2.2 Supporting Modules
* **`config.py`**: Central repository for global variables and SQL search patterns. It defines `PATTERNS_GLOB` to customize recognition of XCCL communications, memory operations, and Megatron-LM CPU steps.
* **`query_utils.py`**: Provides the low-level interface to the Perfetto `TraceProcessor`. It implements the `TraceAnalyzer` class to map asynchronous GPU kernels back to their parent CPU "Launch" slices via correlation mapping, automatically identifying CPU thread/process associations.
* **`batch_analyzer.py`**: A multi-processed wrapper optimized for large-scale clusters. It scans directory trees to process multiple rank traces simultaneously, significantly reducing analysis time for full training jobs.

### 2.3 Running Demos
Both `core_analyzer.py` and `batch_analyzer.py` feature `main()` functions for standalone execution.


> [!NOTE]
> **Data Access:** Raw `.trace.json` files are **not included** in this repository due to large sizes. To test these demos, please contact the author for sample data or follow the [**Megatron Patch**](./megatron-patch) instructions to generate your own trace files.

#### Single Trace Analysis
Use this for analyzing a specific rank's trace file.
```bash
python core_analyzer.py --input "/path/to/your/rankXX.XXXXXXX.pt.trace.json"
```

#### Batch Analysis Demo
Use this to process multiple iterations or multiple ranks in parallel. The following example demonstrates how to process traces across 10 parallel processes for a specific iteration folder:

```bash
python batch_analyzer.py --input "/path/to/your_trace_folder" --folders "iteration_15" --processes 10
```
---
## 3. Aggregation & Visualization

### 3.1 `aggregator.py` (Core Logic)
The high-level orchestrator that merges analyzed data from multiple ranks to reconstruct the global training timeline. It performs three key levels of aggregation:
* **Rank-Level Aggregation:** Merges micro-batch steps within a single rank to quantify computation, communication, and their specific overlap.
* **Pipeline Parallel (PP) Group Visualization:** Automatically identifies PP groups from the configuration file and generates multi-rank timelines, aligning ranks to visualize pipeline bubbles and dependencies.
* **Model Group Concatenation:** Stitches together multiple PP groups to visualize the behavior of a full model replica.

**Key Impact:** Provides a macroscopic view of distributed training, enabling users to see how different ranks interact and identify global inefficiencies like pipeline bubbles or uneven workload distribution.

### 3.2 Supporting Modules
* **`interval_proc.py`**: Utilities for merging time intervals and calculating precise metrics for computation, communication, and their overlap.
* **`visualizer.py`**: Matplotlib-based plotting engine with intelligent auto-layout to generate readable Gantt charts from complex, overlapping trace data.

### 3.3 Running Demos

#### Aggregation Demo
After running the `batch_analyzer.py` to generate kernel analysis for all ranks, use the aggregator to visualize the global timeline.

**Single Iteration Mode:**
Process a specific iteration folder containing the analyzed parquet files.
```bash
python aggregator.py --input "/path/to/your/iteration_15" --time-alignment global
```

**Batch Iteration Mode:**
Process multiple iterations at once by specifying the base directory and iteration folder names.
```bash
python aggregator.py --base-folder "/path/to/profile_data" --iterations "iteration_15" "iteration_16" --processes 8
```
### 3.4 Visualization Outputs
The `aggregator.py` script generates a structured hierarchy of visualization folders. Below is a guide to the key output artifacts you can find in the results directory:

* **[Rank-Level Analysis](./result_figs/rank4.1767595720694.pt.trace_kernel_analysis/)**
    * Contains analysis artifacts for individual ranks.
    * `overlapping_timeline.png`: A timeline visualization where different kernel categories (e.g., computation, communication) are aligned by Wall Clock Time, grouped by the micro-batch step (MBS) they belong to.
    * `comm_comp_overlap_combined_rankX.png`: A bar chart analysis quantifying the latency of computation, communication, and their overlap for each MBS.

* **[Pipeline Parallel (PP) Groups](./result_figs/PP_group_0/)**
    * Contains aggregated timelines for specific Pipeline Parallel groups.
    * `pp_group_X_ranks_..._global.png`: A multi-rank Gantt chart showing the timelines of ranks in a PP group.

* **[Full Model Groups](./result_figs/Model_Group_0/)**
    * Represents a complete model replica.
    * `Model_Group_X_all_pp_groups_concatenated.png`: A stitched visualization of all PP groups within a model replica.